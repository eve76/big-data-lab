{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "train_path = 'train.csv'\r\n",
    "\r\n",
    "data = pd.read_csv(train_path)\r\n",
    "label = data.score\r\n",
    "text = data.text\r\n",
    "# print(score)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import nltk\r\n",
    "# nltk.download()\r\n",
    "from nltk.corpus import stopwords\r\n",
    "stops = set(stopwords.words(\"english\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import re\r\n",
    "\r\n",
    "def comment_to_words(text):\r\n",
    "    '''\r\n",
    "    数据清理，去掉表情等非单词数据\r\n",
    "    '''\r\n",
    "    text = BeautifulSoup(text).get_text()\r\n",
    "\r\n",
    "    words = re.sub(\"[^a-zA-Z]\", \" \", text)\r\n",
    "    words = words.lower().split()\r\n",
    "    words = [w for w in words if not w in stops]\r\n",
    "\r\n",
    "    words = \" \".join(words)\r\n",
    "\r\n",
    "    return words\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tqdm import tqdm\r\n",
    "n_comments = text.size\r\n",
    "word_comments = []\r\n",
    "for i in tqdm(range(n_comments)):\r\n",
    "    word_comments.append(comment_to_words(text[i]))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7500/7500 [00:01<00:00, 5908.37it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \\\r\n",
    "    preprocessor = None, stop_words = None, max_features = 10000)\r\n",
    "train_features = vectorizer.fit_transform(word_comments)\r\n",
    "train_features = train_features.toarray()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB \r\n",
    "model = MNB()\r\n",
    "model.fit(train_features, label)\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import numpy as np \r\n",
    "import sklearn\r\n",
    "\r\n",
    "score = np.mean(sklearn.model_selection.cross_val_score(model, train_features, label, cv=50, scoring='roc_auc'))\r\n",
    "print(\"20交叉验证得分：\", score)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20交叉验证得分： 0.8835420414098308\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_path = \"test.csv\"\r\n",
    "test_data = pd.read_csv(test_path)\r\n",
    "# print(test_data)\r\n",
    "test_text = test_data.text\r\n",
    "test_label = test_data.score\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(test_label.index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RangeIndex(start=0, stop=2500, step=1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "test_word_comments = []\r\n",
    "for i in tqdm(range(len(test_text))):\r\n",
    "    test_word_comments.append(comment_to_words(test_text[i]))\r\n",
    "# test_vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \\\r\n",
    "    # preprocessor = None, stop_words = None, max_features = 10000)\r\n",
    "test_features = vectorizer.transform(test_word_comments)\r\n",
    "test_features = test_features.toarray()\r\n",
    "\r\n",
    "result = model.predict(test_features)\r\n",
    "output = pd.DataFrame(data={\"score\":result})\r\n",
    "output.to_csv('result.csv', index = False, quoting=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2500/2500 [00:00<00:00, 5858.36it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\r\n",
    "def acc(result, label):\r\n",
    "    count = 0\r\n",
    "    for i in range(len(result)):\r\n",
    "        if result[i]==label[i]:\r\n",
    "            count += 1\r\n",
    "        else:\r\n",
    "            continue\r\n",
    "    acc = count/len(label)\r\n",
    "    print('accuracy is :',acc)\r\n",
    "acc(result, test_label)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy is : 0.8272\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "eval_path = \"evaluation.csv\"\r\n",
    "eval_data = pd.read_csv(eval_path)\r\n",
    "# print(test_data)\r\n",
    "eval_text = eval_data.text\r\n",
    "eval_label = eval_data.score\r\n",
    "eval_word_comments = []\r\n",
    "for i in tqdm(range(len(eval_text))):\r\n",
    "    eval_word_comments.append(comment_to_words(eval_text[i]))\r\n",
    "# test_vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \\\r\n",
    "    # preprocessor = None, stop_words = None, max_features = 10000)\r\n",
    "eval_features = vectorizer.transform(eval_word_comments)\r\n",
    "eval_features = eval_features.toarray()\r\n",
    "\r\n",
    "eval_result = model.predict(eval_features)\r\n",
    "acc(eval_result, eval_label)\r\n",
    "# output = pd.DataFrame(data={\"score\":eval_result})\r\n",
    "# output.to_csv('result.csv', index = False, quoting=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 7955.03it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy is : 0.8176\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "e37a6a48f9304d19c34ecab5f987c6aae4abb2c1e936b508333bf36acbe97a24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}